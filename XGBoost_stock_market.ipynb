{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jg4726/public-file/blob/main/XGBoost_stock_market.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1136bc",
      "metadata": {
        "id": "ad1136bc"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "pd.set_option('display.max_columns', 500)\n",
        "import cufflinks\n",
        "import cufflinks as cf\n",
        "import plotly.figure_factory as ff\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import *\n",
        "print(\"XGBoost version:\", xgb.__version__)\n",
        "from tqdm.notebook import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c9587a7",
      "metadata": {
        "id": "3c9587a7"
      },
      "outputs": [],
      "source": [
        "# get data[pre-cleaned] from path\n",
        "path = '../project/jspp/'\n",
        "\n",
        "train = pd.read_csv(path+'train.csv')\n",
        "features = pd.read_csv(path+'features.csv')\n",
        "example_test = pd.read_csv(path+'example_test.csv')\n",
        "sample_prediction_df = pd.read_csv(path+'example_sample_submission.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f27d459",
      "metadata": {
        "id": "9f27d459"
      },
      "outputs": [],
      "source": [
        "def reduce_mem_usage(props): #reduce memory usage method from paper [1]\n",
        "    \n",
        "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
        "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
        "    NAlist = []\n",
        "    for col in props.columns:\n",
        "        if props[col].dtype != object:  # Exclude strings\n",
        "\n",
        "            # Print current column type\n",
        "            # print(\"******************************\")\n",
        "            # print(\"Column: \",col)\n",
        "            # print(\"dtype before: \",props[col].dtype)\n",
        "\n",
        "            IsInt = False\n",
        "            mx = props[col].max()\n",
        "            mn = props[col].min()\n",
        "\n",
        "            # Integer does not support NA, therefore, NA needs to be filled\n",
        "            if not np.isfinite(props[col]).all(): \n",
        "                NAlist.append(col)\n",
        "                props[col].fillna(mn-1,inplace=True)  \n",
        "\n",
        "            # test if column can be converted to an integer\n",
        "            asint = props[col].fillna(0).astype(np.int64)\n",
        "            result = (props[col] - asint)\n",
        "            result = result.sum()\n",
        "            if result > -0.01 and result < 0.01:\n",
        "                IsInt = True\n",
        "\n",
        "            # Make Integer/unsigned Integer datatypes\n",
        "            if IsInt:\n",
        "                if mn >= 0:\n",
        "                    if mx < 255:\n",
        "                        props[col] = props[col].astype(np.uint8)\n",
        "                    elif mx < 65535:\n",
        "                        props[col] = props[col].astype(np.uint16)\n",
        "                    elif mx < 4294967295:\n",
        "                        props[col] = props[col].astype(np.uint32)\n",
        "                    else:\n",
        "                        props[col] = props[col].astype(np.uint64)\n",
        "                else:\n",
        "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
        "                        props[col] = props[col].astype(np.int8)\n",
        "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
        "                        props[col] = props[col].astype(np.int16)\n",
        "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
        "                        props[col] = props[col].astype(np.int32)\n",
        "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
        "                        props[col] = props[col].astype(np.int64)    \n",
        "\n",
        "            # Make float datatypes 32 bit\n",
        "            else:\n",
        "                props[col] = props[col].astype(np.float32)\n",
        "\n",
        "            # Print new column type\n",
        "            # print(\"dtype after: \",props[col].dtype)\n",
        "            # print(\"******************************\")\n",
        "\n",
        "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
        "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
        "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
        "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
        "    return props, NAlist\n",
        "\n",
        "train, _ = reduce_mem_usage(train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87296eb0",
      "metadata": {
        "id": "87296eb0"
      },
      "outputs": [],
      "source": [
        "#Set up the training set and labels and exclude some outliers by the feature-importance-over-time-for-outlier-detection method\n",
        "\n",
        "exclude = set([2,5,19,26,29,36,37,43,63,77,87,173,262,264,268,270,276,294,347,499])\n",
        "train = train[~train.date.isin(exclude)]\n",
        "\n",
        "features = [c for c in train.columns if 'feature' in c]\n",
        "\n",
        "train = train[train.weight>0]\n",
        "\n",
        "train['action'] = ((train['resp'].values) > 0).astype('int')\n",
        "train['action1'] = ((train['resp_1'].values) > 0).astype('int')\n",
        "train['action2'] = ((train['resp_2'].values) > 0).astype('int')\n",
        "train['action3'] = ((train['resp_3'].values) > 0).astype('int')\n",
        "train['action4'] = ((train['resp_4'].values) > 0).astype('int')\n",
        "\n",
        "X = train.loc[:, train.columns.str.contains('feature')]\n",
        "y = train.loc[:, 'action3'].astype('int').values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4635614a",
      "metadata": {
        "id": "4635614a"
      },
      "outputs": [],
      "source": [
        "#set up the model parameters \n",
        "\n",
        "clf2 = xgb.XGBClassifier(\n",
        "      n_estimators=400,\n",
        "      max_depth=11,\n",
        "      learning_rate=0.05,\n",
        "      subsample=0.90,\n",
        "      colsample_bytree=0.7,\n",
        "      missing=-999,\n",
        "      random_state=20,\n",
        "      tree_method='gpu_hist', \n",
        "      reg_alpha=10,\n",
        "      reg_lambda=10,\n",
        ")\n",
        "\n",
        "clf2.fit(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d292c3da",
      "metadata": {
        "id": "d292c3da"
      },
      "outputs": [],
      "source": [
        "# initialize the environment and test the model to get a result \n",
        "\n",
        "import janestreet\n",
        "env = janestreet.make_env() \n",
        "iter_test = env.iter_test() # an iterator which loops over the test set\n",
        "\n",
        "tofill = f_mean.values.reshape((1,-1))\n",
        "for (test_df, sample_prediction_df) in iter_test:\n",
        "\n",
        "\n",
        "    if test_df['weight'].values[0] == 0:\n",
        "        sample_prediction_df.action = 0\n",
        "    else:\n",
        "        X_test = test_df.loc[:, features].values\n",
        "        if np.isnan(X_test.sum()):\n",
        "            X_test[0,1:] = np.where(np.isnan(X_test[0,1:]), tofill, X_test[0,1:])\n",
        "        y_preds = int((clf2.predict_proba(X_test)[0][1])>0.5)\n",
        "        sample_prediction_df.action = y_preds\n",
        "    env.predict(sample_prediction_df)\n",
        "\n",
        "    \n",
        "    ###ENDS HERE### ###BELOW ARE SOME METHODS WE DIDN'T USE BUT TRIED###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c49b454",
      "metadata": {
        "id": "3c49b454"
      },
      "outputs": [],
      "source": [
        "#Set income as loss [method from paper[2]]\n",
        "#The result is lower so we didn't include it. Maybe something was not set correctly during the process. \n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from random import choices\n",
        "\n",
        "SEED = 88\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "train = pd.read_csv('../project/jspp/train.csv')\n",
        "train = train.query('date > 85').reset_index(drop = True) \n",
        "train = train[train['weight'] != 0]\n",
        "\n",
        "train.fillna(train.mean(),inplace=True)\n",
        "\n",
        "train['action'] = ((train['resp'].values) > 0).astype(int)\n",
        "\n",
        "\n",
        "features = [c for c in train.columns if \"feature\" in c]\n",
        "\n",
        "f_mean = np.mean(train[features[1:]].values,axis=0)\n",
        "\n",
        "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']\n",
        "\n",
        "X_train = train.loc[:, train.columns.str.contains('feature')]\n",
        "\n",
        "y_train = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T\n",
        "y_train2 = np.stack([train[c].values*train['weight'].values  for c in resp_cols]).T\n",
        "\n",
        "#Model training and fine-tuning\n",
        "def create_mlp(\n",
        "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
        "):\n",
        "\n",
        "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
        "    x = tf.keras.layers.BatchNormalization()(inp)\n",
        "    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
        "    for i in range(len(hidden_units)):\n",
        "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(num_labels)(x)\n",
        "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
        "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "batch_size = 5000\n",
        "hidden_units = [150, 150, 150]\n",
        "dropout_rates = [0.2, 0.2, 0.2, 0.2]\n",
        "label_smoothing = 1e-2\n",
        "learning_rate = 1e-3\n",
        "\n",
        "clf = create_mlp(\n",
        "    len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
        "    )\n",
        "# 200 rounds of normal training\n",
        "clf.fit(X_train, y_train, epochs=200, batch_size=5000, shuffle=True)\n",
        "\n",
        "def score_loss(y_true, y_pred):\n",
        "    score = -tf.reduce_sum(tf.cast(y_true, 'float32')[:,3] * tf.cast(y_pred, 'float32')[:,3]) \n",
        "    return score\n",
        "\n",
        "# Fine-tuning 10 rounds\n",
        "clf.compile(loss=score_loss,\n",
        "                optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "                metrics='AUC',\n",
        "              )\n",
        "history = clf.fit(X_train, y_train2, epochs=10, batch_size=batch_size, shuffle=True)\n",
        "clf.save_weights('weight.h5')\n",
        "\n",
        "\n",
        "\n",
        "#The result is even lower than the poor XGBoost itself\n",
        "\n",
        "th = 0.5000\n",
        "f = np.median\n",
        "\n",
        "import janestreet\n",
        "env = janestreet.make_env()\n",
        "for (test_df, pred_df) in tqdm(env.iter_test()):\n",
        "    if test_df['weight'].item() > 0:\n",
        "        x_tt = test_df.loc[:, features].values\n",
        "        if np.isnan(x_tt[:, 1:].sum()):\n",
        "            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n",
        "        pred = clf(x_tt, training = False).numpy()[0][2] \n",
        "        pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n",
        "    else:\n",
        "        pred_df.action = 0\n",
        "    env.predict(pred_df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "XGBoost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}